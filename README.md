# Hand-Interface-System-Control

This project implements a gesture-controlled virtual mouse system that enables hands-free interaction with a computer using real-time hand gestures. Leveraging Python, OpenCV, and MediaPipe, the system captures live video input from a webcam and accurately tracks specific hand landmarks to perform mouse operations. The movement of the index finger controls the cursor, while custom gesture combinations—such as pinching or specific finger positions—are mapped to actions like left-click, right-click, scrolling, and drag-and-drop. This approach eliminates the need for traditional hardware devices, offering an intuitive, contactless, and accessible method of system navigation. The project demonstrates the integration of computer vision and human-computer interaction, with potential applications in assistive technology, smart interfaces, and touchless computing environments.
